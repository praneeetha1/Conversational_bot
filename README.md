# Job Data Conversational Chatbot
A conversational bot built using LangChain and LLM using a jobs dataset that I extracted from careers pages.

This project is a **Retrieval-Augmented Generation (RAG)** based chatbot that helps job seekers explore and query job listings in a conversational manner. It loads job data from CSVs, creates semantic embeddings, and uses a local Llama 2 model to provide accurate, context-based answers.

The chatbot runs locally, ensuring **privacy** and **offline capability**.

## Project Overview
**Problem:** Job seekers need quick, accurate, searchable access to large datasets of job postings.  
**Solution:** A RAG pipeline that performs semantic search over job data and generates factual answers constrained to your dataset.  
**Why Local:** Offline usage, low cost, enhanced data privacy.

## ğŸš€ Features
- **Load and validate CSVs** with schema: `title`, `company`, `job_description`, `key_skills`
- **Semantic search** via **FAISS** for fast retrieval
- **Embeddings** from HuggingFace `all-MiniLM-L6-v2`
- **Local language model inference** with LLaMA 2 (via **LlamaCpp**)
- **Conversational memory** for multiâ€‘turn Q&A
- **Custom prompt** to ensure factual, datasetâ€‘grounded responses
- **Streamlit UI** with styled chat bubbles

## ğŸ“‚ Data Requirement
> **Note:** This repository does **not** include job CSV data.  
> You must add your own CSV files into the `data/` directory before running the chatbot.  
> Each CSV **must** have the following columns:

| Column           | Type   | Description |
|------------------|--------|-------------|
| `title`          | string | Job title/role |
| `company`        | string | Company name |
| `job_description`| text   | Full job description |
| `key_skills`     | text   | Comma/pipeâ€‘separated skills |

**Example CSV:**
title,company,job_description,key_skills
Data Scientist,ABC Corp,"Analyze large datasets and build ML models","Python,SQL,Machine Learning"
Backend Engineer,XYZ Ltd,"Develop backend APIs and maintain databases","Django,PostgreSQL,Docker"

## ğŸ“‚ Repository Structure
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ conversationalbot.py # Streamlit app entry point
â”œâ”€â”€ data/ # Your CSV job data (user must add)
â”œâ”€â”€ vectorstore/ # Auto-generated FAISS database
â”œâ”€â”€ .env # Environment config (optional)
â””â”€â”€ Interface.png # UI screenshot (optional)


## âš™ï¸ How It Works
1. **Load CSV data** from `data/`
2. **Validate schema** for required columns
3. Convert each job posting into a **text document**
4. **Generate embeddings** (HuggingFace MiniLM-L6-v2)
5. Store vectors in **FAISS**
6. **Retriever** fetches topâ€‘K matches for a query
7. **LLaMA 2** generates an answer using retrieved documents + chat history
8. Display results in the **Streamlit chat interface**


## ğŸ–¥ï¸ Quickstart

### 1ï¸âƒ£ Clone & Install Dependencies
git clone <your-repo-url>
cd <your-repo>
pip install -r requirements.txt

### 2ï¸âƒ£ Download Model
Download a **LLaMAâ€‘2â€‘7Bâ€‘Chat** `.gguf` file (e.g., `llama-2-7b-chat.Q4_K_M.gguf`).  
Save it in the project root and update the `model_path` in `conversationalbot.py`:
model_path="llama-2-7b-chat.Q4_K_M.gguf"


### 3ï¸âƒ£ Add Your CSV Data
Place one or more CSV files following the schema into the `data/` folder.

### 4ï¸âƒ£ Run the App
streamlit run conversationalbot.py

### 5ï¸âƒ£ Using the Chatbot
- Click **"Load and Process Documents"** in the sidebar.
- Ask natural language questions like:
  - "What skills are required for a Data Analyst position?"
  - "List backend roles that require Django."
  - "Which companies are offering remote work?"

---

## âš™ï¸ Configuration
- Retriever search depth:  
search_kwargs={"k": 3}
- Model generation params:
- `temperature`
- `max_tokens`
- `n_ctx`
- Prompt defined in `llmtemplate` for style/tone

---

## ğŸ›  Troubleshooting
- **No CSVs found** â†’ Ensure your files are in the `data/` folder
- **Missing columns** â†’ Match required schema exactly
- **Slow performance** â†’ First run takes longer to embed data
- **Out of memory** â†’ Try smaller `.gguf` model or reduce `n_ctx`

---

## ğŸ”’ Privacy
- Entire pipeline runs locally once model + CSVs are provided  
- No external API calls â€” your job data never leaves your system

---

## ğŸ“š Tech Stack
- **Python**  
- **Pandas** â€” CSV parsing & preprocessing  
- **FAISS** â€” vector similarity search  
- **HuggingFace sentence-transformers** â€” embeddings  
- **LangChain** â€” retrieval + LLM orchestration  
- **LlamaCpp** â€” local LLaMA 2 inference  
- **Streamlit** â€” web UI  

---

## ğŸ“¸ Demo
![Chatbot Interface](Interface.png)

